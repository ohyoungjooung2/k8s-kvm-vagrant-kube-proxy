This doc explains how to install kubectl PersistentVolume and PersistentVolumeClaim using outer nfs server.
We should prepare nfs node.(10.1.0.6 is my nfs server installed kvm env.
I refered below link. That is very awesome github. Thank you.
https://github.com/kubernetes-incubator/external-storage/blob/master/nfs-client/deploy/
1.Nfs sERver install on centos7
 - 10.1.0.6 is nfs server


2. deployment. Create deployment.
[vagrant@kubemaster storage_test]$ cat dep-for-mysql-stor.yml 


[vagrant@kubemaster pvc]$ cat ext-nfs-pro.yml 
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nfs-client-provisioner
---
kind: Deployment
apiVersion: extensions/v1beta1
metadata:
  name: nfs-client-provisioner
spec:
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: nfs-client-provisioner
    spec:
      serviceAccountName: nfs-client-provisioner
      containers:
        - name: nfs-client-provisioner
          image: quay.io/external_storage/nfs-client-provisioner:latest
          volumeMounts:
            - name: nfs-client-root
              mountPath: /persistentvolumes
          env:
            - name: PROVISIONER_NAME
              value: fuseim.pri/ifs
            - name: NFS_SERVER
              value: 10.1.0.6
            - name: NFS_PATH
              value: /nfsroot
      volumes:
        - name: nfs-client-root
          nfs:
            server: 10.1.0.6
            path: /nfsroot


[vagrant@kubemaster pvc]$ kubectl create -f ext-nfs-pro.yml 
serviceaccount/nfs-client-provisioner created
deployment.extensions/nfs-client-provisioner created
[vagrant@kubemaster pvc]$ kubectl get pods
NAME                                      READY     STATUS              RESTARTS   AGE
nfs-client-provisioner-74bc458c8b-rqwqv   0/1       ContainerCreating   0          4s

[vagrant@kubemaster pvc]$ kubectl get pods
NAME                                      READY     STATUS    RESTARTS   AGE
nfs-client-provisioner-74bc458c8b-rqwqv   1/1       Running   0          1m




3. Create class.
[vagrant@kubemaster pvc]$ cat storageClass.yml 
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: managed-nfs-storage
provisioner: fuseim.pri/ifs # or choose another name, must match deployment's env PROVISIONER_NAME'
parameters:
  archiveOnDelete: "false" # When set

[vagrant@kubemaster pvc]$ kubectl create -f storageClass.yml 
storageclass.storage.k8s.io/managed-nfs-storage created

[vagrant@kubemaster pvc]$ kubectl get storageClass | grep managed
managed-nfs-storage         fuseim.pri/ifs      14s



4. Authorization. In my case I installed kubernets 1.11, by default RBAC is configured.
So I need to configure authorization process.

By default RBAC is on.
[vagrant@kubemaster storage_test]$ ps -ef | grep RBAC
root      2916  2884  6 14:00 ?        00:04:28 kube-apiserver --authorization-mode=Node,RBAC \ 
--advertise-address=10.1.0.2 --allow-privileged=true 
--client-ca-file=/etc/kubernetes/pki/ca.crt 
--disable-admission-plugins=PersistentVolumeLabel 
--enable-admission-plugins=NodeRestriction 
--enable-bootstrap-token-auth=true
--etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt 
--etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt 
--etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key
 --etcd-servers=https://127.0.0.1:2379 --insecure-port=0
 --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-key-file=/etc/kubernetes/pki/sa.pub --service-cluster-ip-range=10.96.0.0/12 --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --tls-private-key-file=/etc/kubernetes/pki/apiserver.key


Create authoriztion.
[vagrant@kubemaster pvc]$ vi clusterRoleAuth.yml
[vagrant@kubemaster pvc]$ cat clusterRoleAuth.yml 
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  #name: nfs-client-provisioner-runner
  name: nfs-client-provisioner
rules:
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "create", "delete"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "create", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create", "watch", "list", "get", "update", "patch"]
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]

[vagrant@kubemaster pvc]$ kubectl create -f clusterRoleAuth.yml 
clusterrole.rbac.authorization.k8s.io/nfs-client-provisioner created

[vagrant@kubemaster pvc]$ kubectl get clusterRole | grep nfs
nfs-client-provisioner                                                 30s
[vagrant@kubemaster pvc]$ 


[vagrant@kubemaster pvc]$ vi clusterRoleBinding.yml 
[vagrant@kubemaster pvc]$ cat clusterRoleBinding.yml 
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: nfs-client-provisioner
subjects:
  - kind: ServiceAccount
    name: nfs-client-provisioner
    namespace: default
roleRef:
  kind: ClusterRole
  name: nfs-client-provisioner
  apiGroup: rbac.authorization.k8s.io
[vagrant@kubemaster pvc]$ kubectl create -f clusterRoleBinding.yml 
clusterrolebinding.rbac.authorization.k8s.io/nfs-client-provisioner created

[vagrant@kubemaster pvc]$ kubectl get clusterRoleBinding | grep nfs
nfs-client-provisioner                                 2m
[vagrant@kubemaster pvc]$ 



5.Storage claim(persistentVolumeClaim)
[vagrant@kubemaster pvc]$ vi storageClaimForMySQL.yml

[vagrant@kubemaster pvc]$ cat storageClaimForMySQL.yml 
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: storage-claim-for-mysql
  annotations:
    volume.beta.kubernetes.io/storage-class: "managed-nfs-storage"
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Gi
      
[vagrant@kubemaster pvc]$ kubectl create -f storageClaimForMySQL.yml 
persistentvolumeclaim/storage-claim-for-mysql created

[vagrant@kubemaster pvc]$ kubectl get pvc | grep "storage-claim-for"
storage-claim-for-mysql   Bound     pvc-b64ce916-aeab-11e8-8134-525400366235   1Gi        RWX            managed-nfs-storage   38s



!Congratulations! on us!No errors.
[vagrant@kubemaster pvc]$ kubectl logs nfs-client-provisioner-74bc458c8b-rqwqv

I0902 12:21:31.829007       1 leaderelection.go:194] successfully acquired lease default/fuseim.pri-ifs
I0902 12:21:31.830565       1 controller.go:631] Starting provisioner controller fuseim.pri/ifs_nfs-client-provisioner-74bc458c8b-rqwqv_f98d0588-aea7-11e8-98dc-0a580af4025f!
I0902 12:21:31.830636       1 event.go:221] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"default", Name:"fuseim.pri-ifs", UID:"b9b4a550-aeaa-11e8-8134-525400366235", APIVersion:"v1", ResourceVersion:"287048", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' nfs-client-provisioner-74bc458c8b-rqwqv_f98d0588-aea7-11e8-98dc-0a580af4025f became leader
I0902 12:21:31.930909       1 controller.go:680] Started provisioner controller fuseim.pri/ifs_nfs-client-provisioner-74bc458c8b-rqwqv_f98d0588-aea7-11e8-98dc-0a580af4025f!
I0902 12:28:40.617632       1 controller.go:987] provision "default/storage-claim-for-mysql" class "managed-nfs-storage": started
I0902 12:28:40.626721       1 event.go:221] Event(v1.ObjectReference{Kind:"PersistentVolumeClaim", Namespace:"default", Name:"storage-claim-for-mysql", UID:"b64ce916-aeab-11e8-8134-525400366235", APIVersion:"v1", ResourceVersion:"287903", FieldPath:""}): type: 'Normal' reason: 'Provisioning' External provisioner is provisioning volume for claim "default/storage-claim-for-mysql"
I0902 12:28:40.653522       1 controller.go:1087] provision "default/storage-claim-for-mysql" class "managed-nfs-storage": volume "pvc-b64ce916-aeab-11e8-8134-525400366235" provisioned
I0902 12:28:40.653579       1 controller.go:1101] provision "default/storage-claim-for-mysql" class "managed-nfs-storage": trying to save persistentvvolume "pvc-b64ce916-aeab-11e8-8134-525400366235"
I0902 12:28:40.669980       1 controller.go:1108] provision "default/storage-claim-for-mysql" class "managed-nfs-storage": persistentvolume "pvc-b64ce916-aeab-11e8-8134-525400366235" saved
I0902 12:28:40.670037       1 controller.go:1149] provision "default/storage-claim-for-mysql" class "managed-nfs-storage": succeeded
I0902 12:28:40.670962       1 event.go:221] Event(v1.ObjectReference{Kind:"PersistentVolumeClaim", Namespace:"default", Name:"storage-claim-for-mysql", UID:"b64ce916-aeab-11e8-8134-525400366235", APIVersion:"v1", ResourceVersion:"287903", FieldPath:""}): type: 'Normal' reason: 'ProvisioningSucceeded' Successfully provisioned volume pvc-b64ce916-aeab-11e8-8134-525400366235


Now like Linux volume manager, I claim some storage from external nfs server. Just for dev test, 1Gi.



Now, I will use below link to setup wordpress+mysql on my kvm based vagrant k8s env(11.1)
https://kubernetes.io/docs/tutorials/stateful-application/mysql-wordpress-persistent-volume/

1) Create mysql password
[vagrant@kubemaster storage_test]$ kubectl create secret generic mysql-pass --from-literal=password='enjoypass'
secret/mysql-pass created

[vagrant@kubemaster storage_test]$ kubectl get secrets | grep mysql-pass
mysql-pass                                     Opaque                                1         54s



[vagrant@kubemaster storage_test]$ kubectl describe secrets mysql-pass
Name:         mysql-pass
Namespace:    default
Labels:       <none>
Annotations:  <none>

Type:  Opaque

Data
====
password:  9 bytes


2) Deploy mysql



  name: wordpress-mysql
  labels:
    app: wordpress
spec:
  ports:
    - port: 3306
  selector:
    app: wordpress
    tier: mysql
  clusterIP: None
---
apiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2
kind: Deployment
metadata:
  name: wordpress-mysql
  labels:
    app: wordpress
spec:
  selector:
    matchLabels:
      app: wordpress
      tier: mysql
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: wordpress
        tier: mysql
    spec:
      containers:
      - image: mysql:5.6
        name: mysql
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-pass
              key: password
        ports:
        - containerPort: 3306
          name: mysql
        volumeMounts:
        - name: mysql-persistent-storage
          mountPath: /var/lib/mysql
      volumes:
      - name: mysql-persistent-storage
        persistentVolumeClaim:
          claimName: stor-for-mysql-claim

[vagrant@kubemaster storage_test]$ kubectl create -f mysql-dep.yml 
service/wordpress-mysql created
deployment.apps/wordpress-mysql created

Now running seems ok like belows.

[vagrant@kubemaster storage_test]$ kubectl get pods | grep wordpress
wordpress-mysql-5b768f7c5d-4975p                    0/1       ContainerCreating   0          1m
[vagrant@kubemaster storage_test]$ kubectl get pods | grep wordpress
wordpress-mysql-5b768f7c5d-4975p                    1/1       Running   0          1m

Now it seems very ok like below.
[vagrant@kubemaster storage_test]$ kubectl log wordpress-mysql-5b768f7c5d-4975p | tail -10
log is DEPRECATED and will be removed in a future version. Use logs instead.
2018-08-14 15:39:56 1 [Note] InnoDB: 5.6.41 started; log sequence number 1625997
2018-08-14 15:39:56 1 [Note] Server hostname (bind-address): '*'; port: 3306
2018-08-14 15:39:56 1 [Note] IPv6 is available.
2018-08-14 15:39:56 1 [Note]   - '::' resolves to '::';
2018-08-14 15:39:56 1 [Note] Server socket created on IP: '::'.
2018-08-14 15:39:56 1 [Warning] Insecure configuration for --pid-file: Location '/var/run/mysqld' in the path is accessible to all OS users. Consider choosing a different directory.
2018-08-14 15:39:56 1 [Warning] 'proxies_priv' entry '@ root@wordpress-mysql-5b768f7c5d-4975p' ignored in --skip-name-resolve mode.
2018-08-14 15:39:56 1 [Note] Event Scheduler: Loaded 0 events
2018-08-14 15:39:56 1 [Note] mysqld: ready for connections.
Version: '5.6.41'  socket: '/var/run/mysqld/mysqld.sock'  port: 3306  MySQL Community Server (GPL)

#Like below, We can see mysql wordpress docker ps in one of my kubectl nodes.

vagrant@kubemaster storage_test]$ kubectl get no
NAME          STATUS    ROLES     AGE       VERSION
kubemaster    Ready     master    4d        v1.11.1
kubeworker1   Ready     <none>    4d        v1.11.1
kubeworker2   Ready     <none>    4d        v1.11.1


[vagrant@kubeworker1 ~]$ sudo docker ps | grep mysql | grep word
2ea2c3b09356        mysql@sha256:2e48836690b8416e4890c369aa174fc1f73c125363d94d99cfd08115f4513ec9                                             "docker-entrypoint..."   9 minutes ago       Up 9 minutes                            k8s_mysql_wordpress-mysql-5b768f7c5d-4975p_default_0b441ff6-9fd8-11e8-bf1b-525400cafc29_0
a787d3615930        k8s.gcr.io/pause:3.1                                                                                                      "/pause"                 11 minutes ago      Up 11 minutes                           k8s_POD_wordpress-mysql-5b768f7c5d-4975p_default_0b441ff6-9fd8-11e8-bf1b-525400cafc29_0

3) Deploy wordpress
First, I should create PersistentVolumeClaim as follows.
[vagrant@kubemaster storage_test]$ vi wordpress-stor-claim.yml 
[vagrant@kubemaster storage_test]$ cat wordpress-stor-claim.yml 
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: stor-for-wordpress-claim
  annotations:
    volume.beta.kubernetes.io/storage-class: "managed-nfs-storage-for-mysql"
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Gi



[vagrant@kubemaster storage_test]$ kubectl get pvc | grep word
stor-for-wordpress-claim   Pending                                                                        managed-nfs-storage-for-mysql   11s
[vagrant@kubemaster storage_test]$ kubectl get pvc | grep word
stor-for-wordpress-claim   Bound     pvc-8339364e-9fda-11e8-bf1b-525400cafc29   1Gi        RWX            managed-nfs-storage-for-mysql   12s






[vagrant@kubemaster storage_test]$ vi wordpress-dep.yml 

[vagrant@kubemaster storage_test]$ cat wordpress-dep.yml 
apiVersion: v1
kind: Service
metadata:
  name: wordpress
  labels:
    app: wordpress
spec:
  ports:
    - port: 80
  selector:
    app: wordpress
    tier: frontend
  type: LoadBalancer
---
apiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2
kind: Deployment
metadata:
  name: wordpress
  labels:
    app: wordpress
spec:
  selector:
    matchLabels:
      app: wordpress
      tier: frontend
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: wordpress
        tier: frontend
    spec:
      containers:
      - image: wordpress:4.8-apache
        name: wordpress
        env:
        - name: WORDPRESS_DB_HOST
          value: wordpress-mysql
        - name: WORDPRESS_DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-pass
              key: password
        ports:
        - containerPort: 80
          name: wordpress
        volumeMounts:
        - name: wordpress-persistent-storage
          mountPath: /var/www/html
      volumes:
      - name: wordpress-persistent-storage
        persistentVolumeClaim:
          claimName: stor-for-wordpress-claim

[vagrant@kubemaster storage_test]$ 

[vagrant@kubemaster storage_test]$ #now deploy!
[vagrant@kubemaster storage_test]$ kubectl create -f wordpress-dep.yml 
service/wordpress created
deployment.apps/wordpress created
[vagrant@kubemaster storage_test]$ kubectl get pods | grep wordpress
wordpress-797d7fd654-snknd                          0/1       ContainerCreating   0          9s
wordpress-mysql-5b768f7c5d-4975p                    1/1       Running             0          27m



#Well it takes some time. 
[vagrant@kubemaster storage_test]$ kubectl logs wordpress-797d7fd654-776c5
Error from server (BadRequest): container "wordpress" in pod "wordpress-797d7fd654-776c5" is waiting to start: ContainerCreating
[vagrant@kubemaster storage_test]$ kubectl logs wordpress-797d7fd654-776c5
Error from server (BadRequest): container "wordpress" in pod "wordpress-797d7fd654-776c5" is waiting to start: ContainerCreating
[vagrant@kubemaster storage_test]$ kubectl logs wordpress-797d7fd654-776c5
Error from server (BadRequest): container "wordpress" in pod "wordpress-797d7fd654-776c5" is waiting to start: ContainerCreating
[vagrant@kubemaster storage_test]$ kubectl logs wordpress-797d7fd654-776c5
Error from server (BadRequest): container "wordpress" in pod "wordpress-797d7fd654-776c5" is waiting to start: ContainerCreating
[vagrant@kubemaster storage_test]$ kubectl logs wordpress-797d7fd654-776c5
Error from server (BadRequest): container "wordpress" in pod "wordpress-797d7fd654-776c5" is waiting to start: ContainerCreating
[vagrant@kubemaster storage_test]$ 



[vagrant@kubemaster storage_test]$ kubectl logs wordpress-797d7fd654-776c5
WordPress not found in /var/www/html - copying now...
[vagrant@kubemaster storage_test]$ kubectl logs wordpress-797d7fd654-776c5
WordPress not found in /var/www/html - copying now...
[vagrant@kubemaster storage_test]$ kubectl logs wordpress-797d7fd654-776c5
WordPress not found in /var/www/html - copying now...
[vagrant@kubemaster storage_test]$ kubectl logs wordpress-797d7fd654-776c5
WordPress not found in /var/www/html - copying now...
[vagrant@kubemaster storage_test]$ kubectl logs wordpress-797d7fd654-776c5
WordPress not found in /var/www/html - copying now...
[vagrant@kubemaster storage_test]$ kubectl logs wordpress-797d7fd654-776c5
WordPress not found in /var/www/html - copying now...
[vagrant@kubemaster storage_test]$ kubectl logs wordpress-797d7fd654-776c5
WordPress not found in /var/www/html - copying now...
[vagrant@kubemaster storage_test]$ kubectl logs wordpress-797d7fd654-776c5
WordPress not found in /var/www/html - copying now...
[vagrant@kubemaster storage_test]$ kubectl logs wordpress-797d7fd654-776c5
WordPress not found in /var/www/html - copying now...
[vagrant@kubemaster storage_test]$ kubectl logs wordpress-797d7fd654-776c5
WordPress not found in /var/www/html - copying now...
Complete! WordPress has been successfully copied to /var/www/html



Node port is 30254 and cluster port is of course 80.

[vagrant@kubemaster ~]$ kubectl get svc
NAME              TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
kubernetes        ClusterIP      10.96.0.1       <none>        443/TCP        4d
wordpress         LoadBalancer   10.106.208.28   <pending>     80:30254/TCP   20m
wordpress-mysql   ClusterIP      None            <none>        3306/TCP       1h
[vagrant@kubemaster ~]$ telnet 10.1.0.3 39254
Trying 10.1.0.3...
telnet: connect to address 10.1.0.3: Connection refused
[vagrant@kubemaster ~]$ telnet 10.1.0.3 30254
Trying 10.1.0.3...
Connected to 10.1.0.3.
Escape character is '^]'.
^C^]
telnet> quit
Connection closed.
[vagrant@kubemaster ~]$ telnet 10.1.0.4 30254
Trying 10.1.0.4...
Connected to 10.1.0.4.
Escape character is '^]'.
^]

With browser connect below link, will show wordpress install page.

http://10.1.0.4:30254/wp-admin/install.php


ssh tunneling for convenient connection to wordpress that is being run in kubernet pod..etc.
[vagrant@kubemaster storage_test]$ ssh -L 9000:10.106.208.28:80 vagrant@10.1.0.2

oyj@oyj-ThinkPad-E465:~/kuber$ ssh -L 9000:localhost:9000 vagrant@10.1.0.2


http://localhost:9000 will suffice.





